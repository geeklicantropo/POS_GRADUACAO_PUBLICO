{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notebook para baixar os metados (incluindo o link do pdf) dos trabalhos no Pantheon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Papers baixados são representados pela classe Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Paper:\n",
    "    title: str\n",
    "    abstract: str\n",
    "    keywords: list[str]\n",
    "    issue_date: str\n",
    "    language: str\n",
    "    paper_pdf: str\n",
    "    abstract_eng: str | None = None\n",
    "    is_ai: bool | None = None\n",
    "    year: int | None = None\n",
    "    id: str | None = None\n",
    "\n",
    "def extract_keywords(s):\n",
    "    b = []\n",
    "    j = 0\n",
    "    for i,c in enumerate(s):\n",
    "        if i < len(s)-1:\n",
    "            if c.islower() and s[i+1].isupper():\n",
    "                b.append(s[j:i+1])\n",
    "                j = i+1\n",
    "        else:\n",
    "            b.append(s[j:])\n",
    "    return b\n",
    "\n",
    "def load_papers(json_file_path):\n",
    "    \n",
    "    with open(json_file_path) as f:\n",
    "        papers_dict_list = json.load(f)\n",
    "       \n",
    "    papers = [Paper(**paper_dict) for paper_dict in papers_dict_list]\n",
    "\n",
    "    if papers[0].__dict__.get('year') is None:\n",
    "        for paper in papers:\n",
    "            paper.year = int(paper.issue_date.split('-')[-1])\n",
    "\n",
    "    return papers\n",
    "\n",
    "def save_papers_to_json(papers: list[Paper], json_file_path):\n",
    "     \n",
    "    papers_as_dicts = [asdict(paper) for paper in papers]\n",
    "     \n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(papers_as_dicts, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Função que recebe uma url do Pantheon com a página listando os trabalhos e baixa o conteúdo da página, salvando as informações de cada trabalho em um objeto Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_papers(url):\n",
    "\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    \n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        ref = link.get('href').split('/')\n",
    "        if len(ref) == 4 and ref[0] == '':\n",
    "            urls.append(link.get('href'))\n",
    "\n",
    "    papers = []\n",
    "    for url in urls:\n",
    "        reqs = requests.get(f'https://pantheon.ufrj.br{url}')\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "        paper_dict = {}\n",
    "        for tr in soup.find(\"table\", class_='table itemDisplayTable'):\n",
    "            if isinstance(tr, bs4.element.NavigableString):\n",
    "                continue\n",
    "            row = [td.text for td in tr.find_all('td')]\n",
    "            key = row[0].split(':')[0].lower().replace(' ', '_').replace('/', '_')\n",
    "            if key in Paper.__dataclass_fields__.keys():\n",
    "                if key == 'abstract' and key in paper_dict:\n",
    "                    key = f'{key}_eng'\n",
    "                if key == 'keywords':\n",
    "                    paper_dict[key] = extract_keywords(row[1])\n",
    "                else:\n",
    "                    paper_dict[key] = row[1]\n",
    "        \n",
    "        pdfs = set()\n",
    "        for link in soup.find_all('a'):\n",
    "            text = link.get('href')\n",
    "            if text[-4:] == '.pdf':\n",
    "                pdfs.add(link.get('href'))\n",
    "\n",
    "        if len(pdfs) == 0:\n",
    "            #print(paper.title)\n",
    "            paper_dict['paper_pdf'] = None\n",
    "        else:\n",
    "            paper_dict['paper_pdf'] = f'https://pantheon.ufrj.br{pdfs.pop()}'\n",
    "\n",
    "        paper = Paper(**paper_dict)\n",
    "        papers.append(paper)  \n",
    "        \n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loop para baixar os dados de todos os trabalhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcc_papers = []\n",
    "\n",
    "for i, index in enumerate(range(0, 14201, 100)):\n",
    "\n",
    "    url = f'https://pantheon.ufrj.br/handle/11422/11/simple-search?query=&filter_field_1=dateIssued&filter_type_1=equals&filter_value_1=%5B2010+TO+2024%5D&sort_by=dc.date.issued_dt&order=asc&rpp=100&etal=0&start={index}'\n",
    "\n",
    "    tcc_papers += get_papers(url)\n",
    "\n",
    "    if (index%1000 == 0 and index != 0) or index in [14100, 14200]:\n",
    "        save_papers_to_json(tcc_papers, json_file_path=f'papers_tcc_{index}.json')\n",
    "        \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Código para baixar o pdf de um paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ''\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"file.pdf\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "        print(\"File downloaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
